services:
  proxy:
    image: nginx:stable-alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/ssl.conf:ro
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./certs:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    networks:
      - aureeq-net
    restart: always

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    environment:
      - OLLAMA_HOST=http://ai-engine:11434
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - ai-engine
    volumes:
      - ./data:/app/data
      - ./model_training/scripts/aureeq.db:/app/model_training/scripts/aureeq.db
    networks:
      - aureeq-net
    restart: always

  ai-engine:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    # No GPU reservation here for broad VPS compatibility
    volumes:
      - ollama_storage:/root/.ollama
    networks:
      - aureeq-net
    restart: always

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    networks:
      - aureeq-net
    restart: always

networks:
  aureeq-net:
    driver: bridge

volumes:
  ollama_storage:
